{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNzxSZVX02oq"
      },
      "outputs": [],
      "source": [
        "from razdel import sentenize, tokenize\n",
        "import pymorphy3\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "with open(\"/content/DOVLATOV_SOBR_SOCH.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "sentences = [s.text for s in sentenize(text)]\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "alcohol_words = ['–≤—ã–ø–∏–ª', '–≤—ã–ø–∏—Ç—å', '–≤–æ–¥–∫–∞', '–ø—å—è–Ω—ã–π', '–æ–ø–æ—Ö–º–µ–ª', '–∑–∞–ø–æ–π', '–±—É—Ç—ã–ª–∫–∞']\n",
        "alcohol_lemmas = {morph.parse(w)[0].normal_form for w in alcohol_words}\n",
        "\n",
        "percept_verbs_raw = ['—É–≤–∏–¥–µ—Ç—å', '–ø–æ—á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å', '—É—Å–ª—ã—à–∞—Ç—å', '–æ—â—É—Ç–∏—Ç—å', '–∑–∞–º–µ—Ç–∏—Ç—å', '—Ä–∞–∑–ª–∏—á–∏—Ç—å', '–æ—â—É—â–∞—Ç—å']\n",
        "percept_lemmas = {morph.parse(w)[0].normal_form for w in percept_verbs_raw}\n",
        "\n",
        "visual_words = {\n",
        "    '—Ä–∞–∑–º—ã—Ç—ã–π', '—Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–π', '—Ç—É–º–∞–Ω–Ω—ã–π', '–º—É—Ç–Ω—ã–π', '—Å–º–∞–∑–∞–Ω–Ω—ã–π',\n",
        "    '–Ω–µ–∂–Ω—ã–π', '–º—è–≥–∫–∏–π', '—Ç—ë–ø–ª—ã–π', '–∑–æ–ª–æ—Ç–∏—Å—Ç—ã–π', '—Å–∏—è—é—â–∏–π',\n",
        "    '—á—ë—Ä–Ω—ã–π', '—Å–µ—Ä—ã–π', '–º—Ä–∞—á–Ω—ã–π', '—è—Ä–∫–∏–π', '—Å–≤–µ—Ç–ª—ã–π'\n",
        "}\n",
        "auditory_words = {\n",
        "    '–≥—É–ª', '—à—É–º', '–∑–≤–æ–Ω', '–∂—É–∂–∂–∞–Ω–∏–µ', '–º–µ—Ä–Ω—ã–π', '—Ç–∏—Ö–∏–π', '–≥—Ä–æ–º–∫–∏–π',\n",
        "    '–ø—Ä–∏–≥–ª—É—à—ë–Ω–Ω—ã–π', '–¥–∞–ª—ë–∫–∏–π', '—Ä–µ–∑–∫–∏–π', '–º–æ–Ω–æ—Ç–æ–Ω–Ω—ã–π'\n",
        "}\n",
        "emotional_words = {\n",
        "    '–≥–∞—Ä–º–æ–Ω–∏—è', '–ø—Ä–∏–º–∏—Ä–µ–Ω–∏–µ', '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—Ç–æ—Å–∫–∞', '—Ä–∞–¥–æ—Å—Ç—å',\n",
        "    '–≥—Ä—É—Å—Ç—å', '—Ç—Ä–µ–≤–æ–≥–∞', '–æ–±–ª–µ–≥—á–µ–Ω–∏–µ', '–≤–æ—Å—Ç–æ—Ä–≥', '–∞–ø–∞—Ç–∏—è',\n",
        "    '—É–º–∏—Ä–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ', '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ', '–ª—é–±–æ–≤—å', '–Ω–µ–Ω–∞–≤–∏—Å—Ç—å'\n",
        "}\n",
        "\n",
        "visual_lemmas = {morph.parse(w)[0].normal_form for w in visual_words}\n",
        "auditory_lemmas = {morph.parse(w)[0].normal_form for w in auditory_words}\n",
        "emotional_lemmas = {morph.parse(w)[0].normal_form for w in emotional_words}\n",
        "\n",
        "emotional_lemmas —á–µ—Ä–µ–∑ normal_form\n",
        "emotional_lemmas = {morph.parse(w)[0].normal_form for w in emotional_words}\n",
        "\n",
        "def get_context_windows(sentences, condition_func, window=3):\n",
        "    contexts = []\n",
        "    for i, sent in enumerate(sentences):\n",
        "        if condition_func(sent):\n",
        "            before = sentences[max(0, i - window):i]\n",
        "            after = sentences[i + 1:i + 1 + window]\n",
        "            contexts.append((sent, \" \".join(before), \" \".join(after)))\n",
        "    return contexts\n",
        "\n",
        "def is_alcohol_sentence(sent):\n",
        "    words = [t.text.lower() for t in tokenize(sent) if t.text.isalpha()]\n",
        "    lemmas = [morph.parse(w)[0].normal_form for w in words]\n",
        "    return any(l in alcohol_lemmas for l in lemmas)\n",
        "\n",
        "alcohol_episodes = get_context_windows(sentences, is_alcohol_sentence, window=3)\n",
        "\n",
        "print(f\" –ù–∞–π–¥–µ–Ω–æ {len(alcohol_episodes)} —ç–ø–∏–∑–æ–¥–æ–≤ —Å –∞–ª–∫–æ–≥–æ–ª–µ–º.\")\n",
        "\n",
        "def extract_percept_descriptions(context_text):\n",
        "   tokens = [t.text.lower() for t in tokenize(context_text) if t.text.isalpha()]\n",
        "   lemmas = [morph.parse(w)[0].normal_form for w in tokens]\n",
        "\n",
        "    percept_positions = [i for i, l in enumerate(lemmas) if l in percept_lemmas]\n",
        "\n",
        "    descriptions = {'visual': [], 'auditory': [], 'emotional': []}\n",
        "\n",
        "        for pos in percept_positions:\n",
        "        start = max(0, pos - 5)\n",
        "        end = min(len(lemmas), pos + 6)\n",
        "        window_lemmas = lemmas[start:end]\n",
        "\n",
        "        for l in window_lemmas:\n",
        "            if l in visual_lemmas:\n",
        "                descriptions['visual'].append(l)\n",
        "            elif l in auditory_lemmas:\n",
        "                descriptions['auditory'].append(l)\n",
        "            elif l in emotional_lemmas:\n",
        "                descriptions['emotional'].append(l)\n",
        "\n",
        "    return descriptions\n",
        "\n",
        "all_descriptions_after = {'visual': [], 'auditory': [], 'emotional': []}\n",
        "all_descriptions_before = {'visual': [], 'auditory': [], 'emotional': []}\n",
        "\n",
        "for _, before_ctx, after_ctx in alcohol_episodes:\n",
        "    desc_before = extract_percept_descriptions(before_ctx)\n",
        "    desc_after = extract_percept_descriptions(after_ctx)\n",
        "\n",
        "    for key in all_descriptions_after:\n",
        "        all_descriptions_after[key].extend(desc_after[key])\n",
        "        all_descriptions_before[key].extend(desc_before[key])\n",
        "\n",
        "def compare_frequencies(before, after, top_n=10):\n",
        "    cnt_before = Counter(before)\n",
        "    cnt_after = Counter(after)\n",
        "    all_words = set(cnt_before.keys()) | set(cnt_after.keys())\n",
        "\n",
        "    if not all_words:\n",
        "        return pd.DataFrame()   DataFrame\n",
        "\n",
        "    data = []\n",
        "    for word in all_words:\n",
        "        data.append({\n",
        "            '–°–ª–æ–≤–æ': word,\n",
        "            '–î–æ': cnt_before[word],\n",
        "            '–ü–æ—Å–ª–µ': cnt_after[word],\n",
        "            '–†–∞–∑–Ω–∏—Ü–∞ (–ü–æ—Å–ª–µ ‚Äì –î–æ)': cnt_after[word] - cnt_before[word]\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df = df.sort_values('–†–∞–∑–Ω–∏—Ü–∞ (–ü–æ—Å–ª–µ ‚Äì –î–æ)', ascending=False)\n",
        "    return df.head(top_n)\n",
        "\n",
        "categories = ['visual', 'auditory', 'emotional']\n",
        "titles = {'visual': '–í–∏–∑—É–∞–ª—å–Ω–æ–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ', 'auditory': '–ê—É–¥–∏–∞–ª—å–Ω–æ–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ', 'emotional': '–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ'}\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, cat in enumerate(categories):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    before = all_descriptions_before[cat]\n",
        "    after = all_descriptions_after[cat]\n",
        "\n",
        "\n",
        "    common_words = set(Counter(before).most_common(8)) | set(Counter(after).most_common(8))\n",
        "    words = list({w for w, _ in common_words})\n",
        "\n",
        "    if not words:\n",
        "        plt.title(titles[cat] + \"\\n(–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)\")\n",
        "        continue\n",
        "\n",
        "    freq_before = [before.count(w) for w in words]\n",
        "    freq_after = [after.count(w) for w in words]\n",
        "\n",
        "    x = range(len(words))\n",
        "    plt.bar([xi - 0.2 for xi in x], freq_before, width=0.4, label='–î–æ', color='lightblue')\n",
        "    plt.bar([xi + 0.2 for xi in x], freq_after, width=0.4, label='–ü–æ—Å–ª–µ', color='lightcoral')\n",
        "    plt.xticks(x, words, rotation=45, ha='right')\n",
        "    plt.title(titles[cat])\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"–¢–æ–ø-10 –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–∏ –ü–û–°–õ–ï —É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –∞–ª–∫–æ–≥–æ–ª—è:\")\n",
        "\n",
        "for cat in categories:\n",
        "    before_list = all_descriptions_before[cat]\n",
        "    after_list = all_descriptions_after[cat]\n",
        "\n",
        "\n",
        "    if not before_list and not after_list:\n",
        "        print(f\"\\nüîπ {titles[cat]}: –Ω–µ—Ç –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π\")\n",
        "        continue\n",
        "\n",
        "    df_diff = compare_frequencies(before_list, after_list)\n",
        "\n",
        "\n",
        "    if df_diff.empty:\n",
        "        print(f\"\\nüîπ {titles[cat]}: –Ω–µ—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nüîπ {titles[cat]}:\")\n",
        "\n",
        "    cols_to_show = ['–°–ª–æ–≤–æ', '–î–æ', '–ü–æ—Å–ª–µ']\n",
        "    if '–†–∞–∑–Ω–∏—Ü–∞ (–ü–æ—Å–ª–µ ‚Äì –î–æ)' in df_diff.columns:\n",
        "        cols_to_show.append('–†–∞–∑–Ω–∏—Ü–∞ (–ü–æ—Å–ª–µ ‚Äì –î–æ)')\n",
        "    display(df_diff[cols_to_show].reset_index(drop=True))\n"
      ]
    }
  ]
}